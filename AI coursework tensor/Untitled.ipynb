{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7e7747",
   "metadata": {},
   "source": [
    "# LeNet5 CNN written in Tensorflow\n",
    "\n",
    "The aim of this is to recreate the architecture laid out in the [orginal 1998 paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n",
    "\n",
    "\n",
    "This is a useful diagram to refer back to:\n",
    "![alt text](https://production-media.paperswithcode.com/methods/LeNet_Original_Image_48T74Lc.jpg \"Lenet5\")\n",
    "\n",
    "Step 1 is to find some data for us to use. The orginal paper uses hand drawn digits so that is exactly what we are going to do. The Modified National Institute of Standards and Technology database or MNIST is the largest database of hand written digits created in 1998. It is also the same dataset that the Lenet CNN was trained on so it makes sense for us to use it as well. You can see in the code snippet below we have split up the data as such:\n",
    "\n",
    "- training set:- 60000 images\n",
    "- test set :- 10000 images\n",
    "- validation set:- 5000 images\n",
    "\n",
    "```python\n",
    "#This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. more info can be found as part of the documentation here: https://keras.io/api/datasets/mnist/\n",
    "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "\n",
    "train_x = tf.expand_dims(train_x, 3)\n",
    "test_x = tf.expand_dims(test_x, 3)\n",
    "\n",
    "val_x = train_x[:5000]\n",
    "val_y = train_y[:5000]\n",
    "```\n",
    "\n",
    "\n",
    "Step 2 is then the model itself. You can see in the comments which each layer is refering too in the diagram however I found this table quite useful as a reference from a medium article:\n",
    "![alt text](https://miro.medium.com/max/1400/1*gNzz6vvWmF6tDN6pTRTd9g.jpeg \"Lenet5\")\n",
    "\n",
    "\n",
    "```python\n",
    "lenet_5_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=train_x[0].shape, padding='same'), #C1\n",
    "    keras.layers.AveragePooling2D(), #S2\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C3\n",
    "    keras.layers.AveragePooling2D(), #S4\n",
    "    keras.layers.Flatten(), #Flatten\n",
    "    keras.layers.Dense(120, activation='tanh'), #C5\n",
    "    keras.layers.Dense(84, activation='tanh'), #F6\n",
    "    keras.layers.Dense(10, activation='softmax') #Output layer\n",
    "])\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983739d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0547127e-03 1.9529670e-04 5.5769593e-03 3.7809465e-02 2.0088479e-03\n",
      "  7.8297465e-04 9.3539035e-01 4.2219663e-06 1.5067049e-02 1.1022537e-04]\n",
      " [2.3157415e-03 2.1374112e-07 1.1909699e-05 1.4094498e-02 9.2303817e-05\n",
      "  5.3169513e-01 6.0677797e-02 4.3817263e-06 5.8117993e-02 3.3299008e-01]\n",
      " [8.4359027e-07 2.0891636e-07 7.7457351e-08 6.0342264e-04 9.9818732e-05\n",
      "  9.8139972e-05 7.1861656e-10 4.6042438e-05 6.8845102e-06 9.9914455e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "new_model = tf.keras.models.load_model('./letnet5.h5')\n",
    "\n",
    "# Check its architecture\n",
    "#new_model.summary()\n",
    "def prep(image):\n",
    "    IMG_SIZE = 28\n",
    "    img_array = cv2.imread(image)  # read in the image\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n",
    "\n",
    "\n",
    "prediction = new_model.predict([prep('./img_10.jpg')])\n",
    "\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
